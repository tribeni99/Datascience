{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e37970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e97fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Required Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56971dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ca356",
   "metadata": {},
   "source": [
    "Scraping all the header tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d54d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=[]\n",
    "for i in soup.find_all('h2', class_=\"mp-h2\"):\n",
    "    headers.append(i.text)\n",
    "headers   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9032e862",
   "metadata": {},
   "source": [
    "#Q3. Pythone program to display IMDB's Top rated 100 Indian movies' data(i.e name,rating,year of release) and make data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending request to the webpage server to get the source code of the page\n",
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "555                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "years = []\n",
    "rates = []\n",
    "ranks = []\n",
    "moviesnm=soup.find('tbody',class_=\"lister-list\").find_all('tr')\n",
    "for i in moviesnm:\n",
    "    name = i.find('td', class_=\"titleColumn\").a.text\n",
    "    names.append(name)\n",
    "    rank = i.find('td', class_=\"titleColumn\").get_text(strip=True).split('.')[0]\n",
    "    ranks.append(rank)\n",
    "    year = i.find('td', class_=\"titleColumn\").span.text.strip('()')\n",
    "    years.append(year)\n",
    "    rating = i.find('td', class_=\"ratingColumn imdbRating\")\n",
    "    rates.append(rating.text.strip())\n",
    "\n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame(index = ranks)\n",
    "df1['Name'] = names\n",
    "df1['Year'] = years\n",
    "df1['Rate'] = rates\n",
    "df1.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746cbe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')\n",
    "moviesName = []\n",
    "moviesYear = []\n",
    "moviesRate = []\n",
    "\n",
    "for table in tables:\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        if len(cells) > 1:\n",
    "            movieName = cells[0]\n",
    "            moviesName.append(movieName.text.strip())\n",
    "            \n",
    "            movieYear = cells[1]\n",
    "            moviesYear.append(movieYear.text.strip())\n",
    "            \n",
    "            movieRate = cells[2]\n",
    "            moviesRate.append(movieRate.text.strip())\n",
    "            \n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame(moviesYear, index = moviesName, columns = ['Year'])\n",
    "df1['Rate'] = moviesRate\n",
    "df1.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d5437",
   "metadata": {},
   "source": [
    "Q2.#Python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    " and make dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778076e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending request to the webpage server to get the source code of the page\n",
    "page = requests.get('https://www.imdb.com/search/title/?groups=top_250&sort=user_rating')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c113292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5521d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=[]\n",
    "for i in soup.find_all('h1',class_=\"header\"):      \n",
    "    movies.append(i.h1.get_text()) \n",
    "    \n",
    "movies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b03f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "years = []\n",
    "rates = []\n",
    "ranks = []\n",
    "for i in soup.find_all('h3',class_=\"lister-item-header\"):      \n",
    "    names.append(i.a.get_text())\n",
    "for i in soup.find_all('span', class_=\"lister-item-index unbold text-primary\"):\n",
    "    ranks.append(i.get_text(strip=True).split('.')[0])\n",
    "for i in soup.find_all('span', class_=\"lister-item-year text-muted unbold\"):\n",
    "    years.append(i.text.strip('()'))\n",
    "for i in soup.find_all('div', class_=\"inline-block ratings-imdb-rating\"):\n",
    "    rates.append(i.text.strip())\n",
    "\n",
    "import pandas as pd\n",
    "df1 = pd.DataFrame(index = ranks)\n",
    "df1['Name'] = names\n",
    "df1['Year'] = years\n",
    "df1['Rate'] = rates\n",
    "df1.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cf828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next 50 cells\n",
    "#sending request to the webpage server to get the source code of the page\n",
    "page = requests.get('https://www.imdb.com/search/title/?groups=top_250&sort=user_rating,desc&start=51&view=advanced')\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201eb4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next 50 movies\n",
    "names = []\n",
    "years = []\n",
    "rates = []\n",
    "ranks = []\n",
    "for i in soup.find_all('h3',class_=\"lister-item-header\"):      \n",
    "    names.append(i.a.get_text())\n",
    "for i in soup.find_all('span', class_=\"lister-item-index unbold text-primary\"):\n",
    "    ranks.append(i.get_text(strip=True).split('.')[0])\n",
    "for i in soup.find_all('span', class_=\"lister-item-year text-muted unbold\"):\n",
    "    years.append(i.text.strip('()'))\n",
    "for i in soup.find_all('div', class_=\"inline-block ratings-imdb-rating\"):\n",
    "    rates.append(i.text.strip())\n",
    "\n",
    "import pandas as pd\n",
    "df2 = pd.DataFrame(index = ranks)\n",
    "df2['Name'] = names\n",
    "df2['Year'] = years\n",
    "df2['Rate'] = rates\n",
    "df3=df1.append([df2])\n",
    "df3 # 100 top movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf495d82",
   "metadata": {},
   "source": [
    "Q8#Python program to scrape mentioned details from dineout.co.in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33203232",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.dineout.co.in/bangalore-restaurants/buffet-special')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9344299",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4923e",
   "metadata": {},
   "source": [
    "Scraping restaurants name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6dc0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    titles.append(i.text)\n",
    "    \n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98dbc7f",
   "metadata": {},
   "source": [
    "Scraping locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a57eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b79e6",
   "metadata": {},
   "source": [
    "Scraping first ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23111886",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "    \n",
    "rating    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317c93e",
   "metadata": {},
   "source": [
    "Scraping  Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423fa513",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in soup.find_all('div',class_=\"img cursor\"):\n",
    "    images.append(i)\n",
    "images  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf739e",
   "metadata": {},
   "source": [
    "Q4)#Python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d57d40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sending request to the webpage server to get the source code of the page\n",
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "odidata=[]\n",
    "teams=[]\n",
    "matchPoint=[]\n",
    "matches= []\n",
    "points = []\n",
    "ratings = []\n",
    "ranks = []\n",
    "for i in soup.find_all('div', class_=\"rankings-block__container full rankings-table\"):\n",
    "    odidata.append(i.get_text().strip())\n",
    "\n",
    "for i in soup.find_all('span', class_=\"u-hide-phablet\"):\n",
    "    if i.get_text()!='':\n",
    "        teams.append(i.get_text().strip(''))\n",
    "\n",
    "for i in soup.find_all('td', class_=\"rankings-block__banner--matches\"):\n",
    "    matchPoint.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"rankings-block__banner--points\"):\n",
    "    matchPoint.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"table-body__cell u-center-text\"):\n",
    "    matchPoint.append(i.get_text())\n",
    "for i in range(0,len(matchPoint),2):\n",
    "    matches.append(matchPoint[i])\n",
    "    points.append(matchPoint[i+1])\n",
    "    \n",
    "for i in soup.find_all('td', class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    ratings.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"table-body__cell u-text-right rating\"):\n",
    "    ratings.append(i.get_text())\n",
    "\n",
    "for i in soup.find_all('td', class_=\"rankings-block__banner--pos\"):\n",
    "    ranks.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"table-body__cell table-body__cell--position u-text-right\"):\n",
    "    ranks.append(i.get_text())   \n",
    "    \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(index = ranks)\n",
    "df['TEAM'] = teams\n",
    "df['MATCHES']=matches\n",
    "df['POINTS']=points\n",
    "df['RATING']=ratings\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c79bb6f",
   "metadata": {},
   "source": [
    "#(b) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f7cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3ec2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    " page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "soup = BeautifulSoup(page.content)\n",
    "teams=[]\n",
    "batsmen= []\n",
    "ratings = []\n",
    "ranks = []\n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--name-large\"):\n",
    "    batsmen.append(i.get_text().strip(''))\n",
    "for i in soup.find_all('td', class_=\"table-body__cell rankings-table__name name\"):\n",
    "    batsmen.append(i.get_text().strip('\\n'))\n",
    "\n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--nationality\"):\n",
    "    teams.append(i.get_text().strip('\\n    '))\n",
    "for i in soup.find_all('span', class_=\"table-body__logo-text\"):\n",
    "    teams.append(i.get_text().strip())\n",
    "\n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--rating\"):\n",
    "    ratings.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"table-body__cell rating\"):\n",
    "    ratings.append(i.get_text())\n",
    "\n",
    "for i in soup.find_all('span', class_=\"rankings-block__pos-number\"):\n",
    "    ranks.extend(i.get_text().split())\n",
    "for i in soup.find_all('span', class_=\"rankings-table__pos-number\"):\n",
    "    ranks.append(i.get_text().split()[0]) \n",
    "\n",
    "df = pd.DataFrame(index = ranks)\n",
    "df['PLAYER']=batsmen\n",
    "df['TEAM'] = teams\n",
    "df['RATING']=ratings\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2595d",
   "metadata": {},
   "source": [
    "#c)Top 10 ODI bowlers along with the records of their team and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "soup = BeautifulSoup(page.content)\n",
    "teams=[]\n",
    "bowlers= []\n",
    "ratings = []\n",
    "ranks = []\n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--name-large\"):\n",
    "    bowlers.append(i.get_text().strip(''))\n",
    "for i in soup.find_all('td', class_=\"table-body__cell rankings-table__name name\"):\n",
    "    bowlers.append(i.get_text().strip('\\n'))\n",
    "\n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--nationality\"):\n",
    "    teams.append(i.get_text().strip('\\n    '))\n",
    "for i in soup.find_all('span', class_=\"table-body__logo-text\"):\n",
    "    teams.append(i.get_text().strip())\n",
    "    \n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--rating\"):\n",
    "    ratings.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"table-body__cell rating\"):\n",
    "    ratings.append(i.get_text())\n",
    "\n",
    "for i in soup.find_all('span', class_=\"rankings-block__pos-number\"):\n",
    "    ranks.extend(i.get_text().split())\n",
    "for i in soup.find_all('span', class_=\"rankings-table__pos-number\"):\n",
    "    ranks.append(i.get_text().split()[0])\n",
    "    \n",
    "df = pd.DataFrame(index = ranks)\n",
    "df['PLAYER']=bowlers\n",
    "df['TEAM'] = teams\n",
    "df['RATING']=ratings\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd9f98",
   "metadata": {},
   "source": [
    "Q5.Python program to scrap cricket rankings from icc-cricket.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c2159",
   "metadata": {},
   "source": [
    "a)Top 10 ODI teams in women's cricket along with the records for matches,points and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "teams=[]\n",
    "matchPoint=[]\n",
    "matches= []\n",
    "points = []\n",
    "ratings = []\n",
    "ranks = []\n",
    "\n",
    "for i in soup.find_all('span', class_=\"u-hide-phablet\"):\n",
    "    if i.get_text()!='':\n",
    "        teams.append(i.get_text().strip(''))\n",
    "\n",
    "for i in soup.find_all('td', class_=\"rankings-block__banner--matches\"):\n",
    "    matchPoint.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"rankings-block__banner--points\"):\n",
    "    matchPoint.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"table-body__cell u-center-text\"):\n",
    "    matchPoint.append(i.get_text())\n",
    "for i in range(0,len(matchPoint),2):\n",
    "    matches.append(matchPoint[i])\n",
    "    points.append(matchPoint[i+1])\n",
    "    \n",
    "for i in soup.find_all('td', class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    ratings.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"table-body__cell u-text-right rating\"):\n",
    "    ratings.append(i.get_text())\n",
    "\n",
    "for i in soup.find_all('td', class_=\"rankings-block__banner--pos\"):\n",
    "    ranks.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"table-body__cell table-body__cell--position u-text-right\"):\n",
    "    ranks.append(i.get_text())   \n",
    "\n",
    "df = pd.DataFrame(index = ranks)\n",
    "df['TEAM'] = teams\n",
    "df['MATCHES']=matches\n",
    "df['POINTS']=points\n",
    "df['RATING']=ratings\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dab6fcb",
   "metadata": {},
   "source": [
    "b)Top 10 women's ODI players along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "teams=[]\n",
    "players= []\n",
    "ratings = []\n",
    "ranks = []\n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--name-large\"):\n",
    "    players.append(i.get_text().strip(''))\n",
    "for i in soup.find_all('td', class_=\"table-body__cell rankings-table__name name\"):\n",
    "    players.append(i.get_text().strip('\\n'))\n",
    "\n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--nationality\"):\n",
    "    teams.append(i.get_text().strip())\n",
    "for i in soup.find_all('span', class_=\"table-body__logo-text\"):\n",
    "    teams.append(i.get_text().strip())\n",
    "    \n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--rating\"):\n",
    "    ratings.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"table-body__cell rating\"):\n",
    "    ratings.append(i.get_text())\n",
    "\n",
    "for i in soup.find_all('span', class_=\"rankings-block__pos-number\"):\n",
    "    ranks.extend(i.get_text().split())\n",
    "for i in soup.find_all('span', class_=\"rankings-table__pos-number\"):\n",
    "    ranks.append(i.get_text().split()[0]) \n",
    "    \n",
    "df = pd.DataFrame(index = ranks)\n",
    "df['PLAYER']=players\n",
    "df['TEAM'] = teams\n",
    "df['RATING']=ratings\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ed5e7",
   "metadata": {},
   "source": [
    "c)Top 10 women's ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81184565",
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "page\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "teams=[]\n",
    "player= []\n",
    "ratings = []\n",
    "ranks = []\n",
    "for i in soup.find_all('div', class_=\"rankings-block__container full\"):\n",
    "    player.append(i.get_text().strip(''))\n",
    "for i in soup.find_all('td', class_=\"table-head__cell\"):\n",
    "    player.append(i.get_text().strip('\\n'))\n",
    "\n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--nationality\"):\n",
    "    teams.append(i.get_text().strip())\n",
    "for i in soup.find_all('span', class_=\"table-body__logo-text\"):\n",
    "    teams.append(i.get_text().strip())\n",
    "    \n",
    "for i in soup.find_all('div', class_=\"rankings-block__banner--rating\"):\n",
    "    ratings.extend(i.get_text().split())\n",
    "for i in soup.find_all('td', class_=\"table-body__cell rating\"):\n",
    "    ratings.append(i.get_text())\n",
    "\n",
    "for i in soup.find_all('span', class_=\"rankings-block__pos-number\"):\n",
    "    ranks.extend(i.get_text().split())\n",
    "for i in soup.find_all('span', class_=\"rankings-table__pos-number\"):\n",
    "    ranks.append(i.get_text().split()[0]) \n",
    "    \n",
    "df = pd.DataFrame\n",
    "df['PLAYER']=all-rounder\n",
    "df['TEAM'] = teams\n",
    "df['RATING']=ratings\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd3dcb",
   "metadata": {},
   "source": [
    "Q10# python program to scrape monument name, monument description, image URL about top 10 monuments\n",
    "from puredestinations.co.uk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Required Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india'\n",
    "reqs=requests.get(url)\n",
    "soup = BeautifulSoup(reqs.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ffe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "description = []\n",
    "im_url = []\n",
    "\n",
    "titles = []\n",
    "allP = soup.find_all('p')\n",
    "\n",
    "for indx,name in enumerate(allP):\n",
    "    local = name.find('strong')\n",
    "    if len(str(local))!=4:\n",
    "        if indx!=34:\n",
    "            names.append(name.find('strong').text)\n",
    "            index=indx\n",
    "            local=allP[index+1]\n",
    "            description.append(local.text)\n",
    "            local2=allP[index+2]\n",
    "            im_url.append(local2.find('img')['data-src'])\n",
    "            \n",
    "df=pd.DataFrame()\n",
    "df['NAME']= names\n",
    "df['DESCRIPTION']= description\n",
    "df['IMAGE URL']= im_url\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f62482",
   "metadata": {},
   "source": [
    "Q6.Python program to scrape details of all the posts from coreyms.com. Scrape the heading, date, content\n",
    "and the code for the video from the link for the youtube video from the post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb23717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Required Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cffda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://coreyms.com/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ded69",
   "metadata": {},
   "outputs": [],
   "source": [
    "heading = []\n",
    "for i in soup.find_all('a',class_=\"entry-title-link\"):\n",
    "    heading.append(i.text)\n",
    "heading  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = []\n",
    "for i in soup.find_all('time',class_=\"entry-time\"):\n",
    "    date.append(i.text)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "for i in soup.find_all('div',class_=\"entry-content\"):\n",
    "    content.append(i.text)\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75be0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytlink = []\n",
    "soup1 = BeautifulSoup(page.text,'html.parser')\n",
    "for i in soup1.find_all('iframe'):\n",
    "    ytlink.append(i.get('src'))\n",
    "ytlink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd22b93",
   "metadata": {},
   "source": [
    "Q7.python program to scrape house details from mentioned URL. It should include house title, location,\n",
    "area, EMI and price from nobroker.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d607ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Required Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc861055",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.nobroker.in/property/rent/bangalore/multiple?searchParam=W3sibGF0IjoxMi45NzgzNjkyLCJsb24iOjc3LjY0MDgzNTYsInBsYWNlSWQiOiJDaElKa1FOM0dLUVdyanNSTmhCUUpyaEdEN1UiLCJwbGFjZU5hbWUiOiJJbmRpcmFuYWdhciJ9LHsibGF0IjoxMi45MzA0Mjc4LCJsb24iOjc3LjY3ODQwNCwicGxhY2VJZCI6IkNoSUpMLWswTG5VVHJqc1JybXFZYjZZMHNzSSIsInBsYWNlTmFtZSI6IkJlbGxhbmR1ciJ9LHsibGF0IjoxMi45MzA3NzM1LCJsb24iOjc3LjU4MzgzMDIsInBsYWNlSWQiOiJDaElKMmRkbFo1Z1ZyanNSaDFCT0FhZi1vcnMiLCJwbGFjZU5hbWUiOiJKYXlhbmFnYXIifV0=&radius=2.0&sharedAccomodation=0&city=bangalore&locality=Indiranagar,&locality=Bellandur,&locality=Jayanagar%27')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "addresses = []\n",
    "rents = []\n",
    "area = []\n",
    "deposits = []\n",
    "furnishings = []\n",
    "property_ages = []\n",
    "available_fors = []\n",
    "immediate_possessions = []\n",
    "for i in soup.find_all('h2',class_=\"heading-6 font-semi-bold nb__25Cl7\"):\n",
    "    titles.extend(i.get_text().split('\\n'))\n",
    "for i in soup.find_all('div', class_='nb__27aDo'):\n",
    "    rents.extend(i.get_text().split('\\n'))\n",
    "for i in soup.find_all('div', class_='nb__FfHqA'):\n",
    "    area.extend(i.get_text().split('\\n'))\n",
    "all = soup.find_all('div', class_='font-semi-bold heading-6')\n",
    "for indx, i in enumerate(all):\n",
    "    if indx != 0 & indx == 1:\n",
    "        deposits.append(i.get_text())\n",
    "    else: \n",
    "        if indx != 0:\n",
    "            if indx < (len(all) - 5):\n",
    "                deposits.append(all[indx + 1].get_text())\n",
    "                \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
